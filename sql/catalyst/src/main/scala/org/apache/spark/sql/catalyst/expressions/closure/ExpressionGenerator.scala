/* Copyright (C) 2016 Databricks, Inc.
 *
 * Portions of this software incorporate or are derived from software contained within Apache Spark,
 * and this modified software differs from the Apache Spark software provided under the Apache
 * License, Version 2.0, a copy of which you may obtain at
 * http://www.apache.org/licenses/LICENSE-2.0
 */

package org.apache.spark.sql.catalyst.expressions.closure

import scala.language.implicitConversions

import org.apache.xbean.asm5.Type
import org.apache.xbean.asm5.Type._

import org.apache.spark.sql.catalyst.InternalRow
import org.apache.spark.sql.catalyst.analysis.caseSensitiveResolution
import org.apache.spark.sql.catalyst.analysis.UnresolvedAttribute
import org.apache.spark.sql.catalyst.expressions.{Add, BinaryArithmetic, BitwiseAnd, BitwiseOr, BitwiseXor, Cast => CastExpression, CreateNamedStruct, EqualNullSafe, Expression, ExtractValue, GreaterThan, GreaterThanOrEqual, If => IfExpression, LeafExpression, LessThan, LessThanOrEqual, Literal, Multiply, Not, Remainder, Subtract, Unevaluable}
import org.apache.spark.sql.catalyst.expressions.closure.TypeOps.typeToTypeOps
import org.apache.spark.sql.catalyst.expressions.codegen.{CodegenContext, CodegenFallback, ExprCode}
import org.apache.spark.sql.catalyst.expressions.objects.AssertNotNull
import org.apache.spark.sql.types.{AbstractDataType, AtomicType, DataType, DoubleType, FloatType, IntegerType, LongType, NullType, ObjectType, StructType, TypeCollection}

/**
 * Translates the Node tree returned from [[ByteCodeParser]] to Spark sql expressions.
 *
 * For example, input Node tree for filter operation:
 *
 * {{{
 *   Arithmetic[Z](>)
 *     Argument[I]
 *     Constant[I](0)
 * }}}
 *
 * is translated to expression:
 *
 * {{{
 *   GreaterThan
 *     ColumnField("value")
 *     Literal(0)
 * }}}
 *
 * After translation, the expression may be further flattened to Seq[Expression] if the expression
 * is a StructType which contains sub-fields. This is consistent with the behavior of Dataset
 * typed Map operation.
 *
 * For example:
 * {{{
 *   // If the type U is a case class, then all fields of type U is flattened. The result Dataset
 *   // may contains multiple fields.
 *   dataset.map(func: T => U)
 * }}}
 */
class ExpressionGenerator {

  /**
   * Generates expressions from the Node tree returned from [[ByteCodeParser]]
   *
   * 1. If the expression after translation's data type doesn't have nested field, like closure for
   * typed Filter which returns a Boolean value, then we return this expression directly to
   * caller.
   * 2. If the expression after translation's data type has nested fields, for example closure for
   * typed Map may return a case class, then we will further flatten the sub-fields of the
   * expression to Seq[Expression].
   *
   * @param nodeTree Node tree generated by [[ByteCodeParser]].
   * @param argumentClass The class of the closure input argument.
   * @param argumentSchema The Spark sql type of the closure input argument
   * @return a Spark sql expression
   * @throws ClosureTranslationException
   */
  def generate(
      nodeTree: Node,
      argumentClass: Class[_],
      argumentSchema: StructType): Seq[Expression] = {
    generate(nodeTree, Type.getType(argumentClass), argumentSchema)
  }

  private def generate(
      nodeTree: Node,
      argumentType: Type,
      argumentSchema: StructType): Seq[Expression] = {

    if (!argumentType.isAtomicType && !argumentType.isProductType) {
      throw new ClosureTranslationException("Closure input argument's type need to be " +
        s"primitive type, or case class. current it's ASM type is: ${argumentType.getClassName}")
    }

    // Traverses the Node tree and translates it to an Expression.
    def visit(node: Node): Expression = node match {
      case Void =>
        throw new ClosureTranslationException(
          "Closure that returns void is not supported")
      // Denotes the closure class object, for example, we may access the private fields of the
      // closure class object.
      case This(dataType) =>
        throw new ClosureTranslationException("Closure that reference free variables like " +
          s"private fields of the closure class is not supported (type: $dataType).")
      // Char type in Byte code is stored and computed as an Integer (zero-extended).
      // For example for closure, (a: Int) => 'c'.toInt, 'c' is treated as an Integer.
      case Constant(constant: Char) => Literal(constant.toInt)
      case c @ Constant(constant) => Literal(constant)
      case Arithmetic(op, left, right, dataType) =>
        op match {
          case "+" => Add(visit(left), visit(right))
          case "-" => Subtract(visit(left), visit(right))
          case "*" => Multiply(visit(left), visit(right))
          case "/" => DivideLikeJVM(visit(left), visit(right))
          case "<" => LessThan(visit(left), visit(right))
          case ">" => GreaterThan(visit(left), visit(right))
          case "<=" => LessThanOrEqual(visit(left), visit(right))
          case ">=" => GreaterThanOrEqual(visit(left), visit(right))
          case "%" => Remainder(visit(left), visit(right))
          case "&" => BitwiseAnd(visit(left), visit(right))
          case "|" => BitwiseOr(visit(left), visit(right))
          case "^" => BitwiseXor(visit(left), visit(right))
          case "!" => Not(visit(left))
          case "==" => EqualNullSafe(visit(left), visit(right))
          case "!=" => Not(EqualNullSafe(visit(left), visit(right)))
          case _ => throw new ClosureTranslationException(s"Unsupported operation $op")
        }
      case Cast(node, dataType) => checkCast(visit(node), node.dataType, dataType)
      case If(condition, left, right, dataType) =>
        IfExpression(visit(condition), visit(left), visit(right))
      // Denotes the input argument of the closure, which is translated to field access
      // of child logical plan.
      case Argument(dataType) =>
        if (dataType.isAtomicType) {
          // For atomic type, the underlying logical plan only has one column, use the column
          // name directly.
          ColumnField(argumentSchema.fieldNames(0) :: Nil, dataType.sqlType)
        } else {
          ColumnField(Seq.empty[String], dataType.sqlType)
        }
      // Static function call.
      case foo @ FunctionCall(_, clazz, method, args, dataType) if isStaticFunction(foo) =>
        (clazz, method) match {
          case _ if isUnboxingMethod(clazz, method) =>
            // For un-boxing, checks whether the argument is null in checkCast.
            checkCast(visit(args(0)), args(0).dataType, dataType)
          case _ if isBoxingMethod(clazz, method) =>
            visit(args(0))
          case _ =>
            throw new ClosureTranslationException(s"Unsupported static function $clazz/$method")
        }
      // Non-static getter function calls
      case foo @ FunctionCall(obj, clazz, method, _, dataType) if isGetterMethod(foo) =>
        visit(obj) match {
          // Access sub-fields of existing column fields
          case ColumnField(fieldPath, _) =>
            // For Tuple class, getter method name may not match with field name.
            // For example, for field "_1", the getter method name maybe is "_1$spI".
            val subField = translateMethodNameToFieldName(clazz, method)
            ColumnField(fieldPath :+ subField, dataType.sqlType)
          case _ =>
            throw new ClosureTranslationException(s"Unsupported getter function call" +
              s" $clazz/$method on object (${obj})")
        }
      // Other non-static function calls are not supported.
      case FunctionCall(_, clazz, method, _, _) =>
        throw new ClosureTranslationException(s"Unsupported function call $clazz/$method")
      case other =>
        throw new ClosureTranslationException(s"Cannot translate Node $other to Expression")
    }

    // Translates the Node tree to an expression
    val expression = visit(nodeTree)

    // Makes sure all ColumnFields in the expression exists in the input argument's schema.
    val resolvedExpression = resolveFields(expression, argumentSchema)

    // Dataset.map(func: T => U) flatten the sub-fields of U if U is a case class.
    // To be consistent with this, we should also flatten expression like "a.b" to
    // expression list "a.b.field1", "a.b.field2"...
    val flattenExpressions: Seq[Expression] = resolvedExpression match {
      case create: CreateNamedStruct =>
        val (_, valueExpressions) =
          create.children.grouped(2).map { case Seq(name, value) => (name, value) }.toList.unzip
        valueExpressions
      case struct if struct.dataType.isInstanceOf[StructType] =>
        val dataType = struct.dataType.asInstanceOf[StructType]
        dataType.fieldNames.map { name =>
          ExtractValue(
            // Top-level row should not be null.
            AssertNotNull(struct, Seq("top level non-flat input object")),
            Literal(name),
            caseSensitiveResolution)
        }
      case other => Seq(other)
    }

    // Add NPE checks
    flattenExpressions.map { expr =>
      expr.transformUp {
        case ColumnField(name :: Nil, dataType) => UnresolvedAttribute(name :: Nil)
        case ColumnField(nameParts, dataType) if nameParts.length > 1 =>
          val parent = UnresolvedAttribute(nameParts.slice(0, nameParts.length - 1))
          NPEOnNull(parent, UnresolvedAttribute(nameParts))
      }
    }
  }

  private val unboxingMethods = List(
    "scala.Predef$" -> "Long2long",
    "scala.Predef$" -> "Float2float",
    "scala.Predef$" -> "Double2double",
    "scala.Predef$" -> "Boolean2boolean",
    "scala.Predef$" -> "Short2short",
    "scala.Predef$" -> "Byte2byte",
    "scala.Predef$" -> "Integer2int"
  ).toSet

  private def isUnboxingMethod(className: String, method: String): Boolean = {
    unboxingMethods.contains((className -> method))
  }

  private val boxingMethods = List(
    "scala.Predef$" -> "long2Long",
    "scala.Predef$" -> "float2Float",
    "scala.Predef$" -> "double2Double",
    "scala.Predef$" -> "boolean2Boolean",
    "scala.Predef$" -> "short2Short",
    "scala.Predef$" -> "byte2Byte",
    "scala.Predef$" -> "int2Integer"
  ).toSet

  private def isBoxingMethod(className: String, method: String): Boolean = {
    boxingMethods.contains(className -> method)
  }

  private def isStaticFunction(foo: FunctionCall): Boolean = {
    foo match {
      case _ if foo.obj == Constant(null) => true
      // Calling method in companion object is treated as calling a static function
      case FunctionCall(StaticField(_, "MODULE$", _), _, _, _, _) => true
      case _ => false
    }
  }

  private def translateMethodNameToFieldName(clazz: String, getter: String): String = clazz match {
    // Scala compiler may generate function call like _1$spI for field access "_1"
    case _ if clazz.startsWith("scala.Tuple") && getter.matches("^_[0-9][0-9]?\\$.*") =>
      getter.substring(0, getter.indexOf("$"))
    // For other cases, the getter name like the case class field name can be directly
    // mapped to Dataset column field name.
    case _ => getter
  }

  // Zero input argument method is treated as a getter
  private def isGetterMethod(foo: FunctionCall): Boolean = {
    !isStaticFunction(foo) &&
      foo.arguments.length == 0 &&
      (foo.dataType.isAtomicType || foo.dataType.isProductType)
  }

  // Make sure all fields can be resolved in schema
  private def resolveFields(expression: Expression, schema: StructType): Expression = {
    val resolvedExpression = expression.transformDown {
      // Accessing top level object
      case ColumnField(Nil, dataType: ObjectType) =>
        val fields = schema.fields.flatMap { field =>
          val name = Literal(field.name)
          val value = ColumnField(field.name :: Nil, field.dataType)
          name :: value :: Nil
        }
        // We use CreateNameStruct instead of CreateStruct because CreateStruct changes the
        // field name to col1, col2, col3...
        CreateNamedStruct(fields)
      // Accessing an ObjectType or StructType field
      case f @ ColumnField(nameParts, dataType) if nameParts.length > 0 &&
        (dataType.isInstanceOf[ObjectType] || dataType.isInstanceOf[StructType]) =>
        // Makes sure all fields can be found in the closure input argument's schema
        findFieldSchema(schema, nameParts) match {
          case structType: StructType =>
            ColumnField(nameParts, structType)
          case actualType =>
            throw new ClosureTranslationException(s"Failed to resolve field $f because " +
              s"required data type $dataType is not compatible with actual type ${actualType}")
        }
      // Accessing a primitive field
      // Makes sure all fields can be found in the closure input argument's schema
      case field @ ColumnField(nameParts, dataType: AtomicType) =>
        // Makes sure all fields can be found in the closure input argument's schema
        val schemaType = findFieldSchema(schema, nameParts)
        // Makes sure the data type matches the corresponding field of input schema
        if (dataType == schemaType) {
          field
        } else {
          throw new ClosureTranslationException(s"Failed to resolve field $field because " +
            s"required data type $dataType mismatch with actual type ${schemaType}")
        }
      case f @ ColumnField(_, dataType) =>
        throw new ClosureTranslationException(s"Failed to resolve field $f")
    }

    // Spark sql If expression's dataType is decided by the left child trueValue's data type.
    // As we relies on the dataType to do type validation. necessary casting is needed to make sure
    // the left child's data type is same as right child's data type.
    resolvedExpression.transformUp {
      case ifExpr @ IfExpression(condition, leftChild, rightChild) =>
        // Make sure the left and right's data type matches.
        val (newLeftChild, newRightChild) =
          (leftChild.dataType, rightChild.dataType) match {
            // Casting NullType
            case (NullType, rightType) => (CastExpression(leftChild, rightType), rightChild)
            case (leftType, NullType) => (leftChild, CastExpression(rightChild, leftType))
            case (leftType, rightType) if leftType == rightType => (leftChild, rightChild)
            case _ =>
              throw new ClosureTranslationException(
                s"Failed to resolve If expression $ifExpr because left branch's data type " +
                  s"${leftChild.dataType} mismatches with right branch's data type " +
                  s"${rightChild.dataType}")
          }
        IfExpression(condition, newLeftChild, newRightChild)
    }
  }

  // Finds the sub-field's schema or throws exception if not found.
  private def findFieldSchema(rootSchema: StructType, fieldPath: Seq[String]): DataType = {
    var schema: DataType = rootSchema
    fieldPath.foreach { fieldName =>
      schema match {
        case struct: StructType if struct.fieldNames.contains(fieldName) =>
          schema = struct(fieldName).dataType
        case _ =>
          throw new ClosureTranslationException(s"Failed to find field $fieldName in $schema")
      }
    }
    schema
  }

  // Casts expression from beforeType to afterType or throws exception if the cast fails.
  private def checkCast(expression: Expression, from: Type, to: Type): Expression = {
    (from, to) match {
      case (before, after) if before == after =>
        expression
      case (before, after) if before.isPrimitiveType && after.isPrimitiveType =>
        if (after == CHAR_TYPE) {
          // Char type need to be handled specially, as catalyst doesn't have this type.
          BitwiseAnd(CastExpression(expression, INT_TYPE.sqlType), Literal(0xffff))
        } else {
          CastExpression(expression, to.sqlType)
        }
      case (before, after) if after.isBoxTypeOf(before) =>
        // boxing, no cast needed.
        expression
      case (before, after) if before.isBoxTypeOf(after) =>
        // unboxing, add NPE check.
        NPEOnNull(expression, expression)
      case (before, after) if before.isNullType && !after.isPrimitiveType =>
        // Casts null to other object type is allowed.
        expression
      case (before, after) if after.isAssignableFrom(before) =>
        // Casts a child class object to parent class object is allowed.
        expression
      case _ =>
        throw new ClosureTranslationException(s"Cannot cast expression ${expression}($from)" +
          s" to ${to}")
    }
  }
}

/**
 * Represents a column field of child logical plan
 */
case class ColumnField(
    nameParts: Seq[String],
    dataType: DataType)
  extends LeafExpression with Unevaluable {

  override def toString: String = s"'${nameParts.mkString(".")}"
  override def nullable: Boolean = true
}

/**
 * Throws exception if condition == null, otherwise returns child expression's evaluation result.
 */
case class NPEOnNull(
    condition: Expression,
    input: Expression)
  extends Expression with CodegenFallback {

  override def children: Seq[Expression] = condition :: input :: Nil

  override def nullable: Boolean = false

  override def dataType: DataType = input.dataType

  override def eval(inputRow: InternalRow): Any = {
    if (condition.eval(inputRow) != null) {
      input.eval(inputRow)
    } else {
      throw new NullPointerException
    }
  }

  override protected def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode = {
    val conditionGen = condition.genCode(ctx)
    val childGen = input.genCode(ctx)
    val code =
      s"""
         |${conditionGen.code}
         |if (${conditionGen.isNull}) {
         |  throw new NullPointerException();
         |}
         |
         |${childGen.code}
         """.stripMargin
    ev.copy(code = code, isNull = "false", value = childGen.value)
  }
}

/**
 * Behaves same as the divide (/) operator in JVM. For example, the following statement throws
 * ArithmeticException.
 * {{{
 *   6 / 0
 * }}}
 */
case class DivideLikeJVM(left: Expression, right: Expression) extends BinaryArithmetic {

  override def inputType: AbstractDataType =
    TypeCollection(IntegerType, LongType, FloatType, DoubleType)

  override def nullable: Boolean = false

  override def symbol: String = "/"

  override def eval(input: InternalRow): Any = {
    val input1 = left.eval(input)
    val input2 = right.eval(input)
    input1 match {
      case f: Float => f / input2.asInstanceOf[java.lang.Float]
      case i: Integer => i / input2.asInstanceOf[java.lang.Integer]
      case l: Long => l / input2.asInstanceOf[java.lang.Long]
      case d: Double => d / input2.asInstanceOf[java.lang.Double]
    }
  }

  override def doGenCode(ctx: CodegenContext, ev: ExprCode): ExprCode = {
    val eval1 = left.genCode(ctx)
    val eval2 = right.genCode(ctx)

    val javaType = ctx.javaType(dataType)
    ev.copy(code =
      s"""
         ${eval1.code}
         ${eval2.code}
         boolean ${ev.isNull} = false;
         $javaType ${ev.value} = ($javaType)(${eval1.value} $symbol ${eval2.value});
       """)
  }
}
